\section{Algorithm for near duplicate detection}
\label{section:luciv}

In the section the improved version of Luciv et.al. algorithm~\cite{luciv2019interactive} is presented.
The utilization of semi-local sequence alignment algorithms in all algorithm phases improves overall time complexity.
%% We now describe an improved version of  by utilizing a \emph{semi-local sa} solution.
%% Then we present proof that improved version preserves completnesess property.
%% It is achieved by imitating all phases of the algorithm. 
It is also proved that the improved algorithm preserves all advantages of the initial one stated at~\cite{luciv2019interactive} such as search completeness.

\subsection{Algorithm description}

As the base one, the presented algorithm consists of three sequential phases.
Moreover, each step of the presented algorithm imitates the corresponding step of the base one.
% As the base one, the presented algorithm comprises three phases.

At the first phase (lines 1-3) semi-local sa problem is solved for pattern $p$ against the whole text $t$.
This solution provides access to the string-substring matrix $H^{str-sub}_{p,t}$ which allows performing fast queries of \emph{sa} score for pattern $p$ against every substring of text $t$.
Then, we construct matrix $M$ by applying transposition and inverse operation implisitly on $H^{str-sub}_{p,t}$:
$$M[j,i]:= -H^{str-sub}_{p,t}[i,j].$$
Note, transposition operation preserves (anti) Monge property whereas inverse operation transforms anti-Monge matrix into the Monge one and vice versa. 
Thus, $M$ is a Monge matrix.

The second phase comprises several steps (Lines 4-6).
First, we want to get for each prefix of the text $t$ the longest suffix that has the highest similarity with the given pattern $p$ with the following constraint.
The lengths of obtained suffixes should be in $|p|*k..\frac{|p|}{k}$ interval where $k \in [\frac{1}{\sqrt{3}},1]$.
It could be done in several ways.
For example, direct pass through diagonal with width $w:= \frac{|p|}{k} - |p|*k = |p|(\frac{1}{k} - k)$ in $H^{str-sub}_{p,t}$ (see fig) or in $M$ (see fig).
The other approach is the following.
Note that in  $M$ is \emph{Monge matrix} and indices are swapped.
It allows us to descry this diagonal as approximately $|t|$ square windows of size $w \times w$ i.e a sliding window of step 1 that goes diagonally.
Because of length constraint we only interesting in elements that lie in the main diagonal and below it (remember, transposition) in these submatrices $w\times w$.
Each of these $W:=wxw$ matrix is \emph{Monge matrix} by definition (as a submatrix of \emph{Monge matrix}).
This implies that $W$ also totally monotone.
If we set to $+\inf$ for elements that lie above the main diagonal that result matrix will remain totally monotone.
Thus, we can apply \emph{SMAWK} algorithm to this matrix to find a leftmost element that has a minimum in a given row with a corresponding column position.
For our case leftmost means that for each prefix algorithm will detect longest suffix (remember that $M$ is transposed $H^{str-sub}_{p,t}$ ).

The second step, it is one-way pass through these suffixes with a sliding window of size $\frac{|p|}{t}$ to find for each window that have alignment score greater or equal to given threshold $-k_{di}$ with pattern $p$ most similar suffix with the longest length. 

The third phase is the same as in \cite{luciv2019interactive} (Lines 8-12).  



\begin{algorithm}[H]
\caption{PATTERN BASED NEAR DUPLICATE
SEARCH ALGORITHM VIA SEMI-LOCAL SA}
\label{alg:patternMathing1}
Input: pattern $p$, text $t$, similiarity measure $k \in  [ \frac{1}{\sqrt{3}} ,1  ]$\\
Output: Set of non-intersected clones of pattern $p$ in text $t$
\begin{equation}
    k_{di}=|p|*(\frac{1}{k}+1)(1-k^2)
\end{equation}
\begin{equation}
 L_{w} = \frac{|p|} {k}
\end{equation}
\begin{equation}
  w = |p|(\frac{1}{k} - k)
\end{equation}
Pseudocode:
\begin{algorithmic}[1]
\STATE{$W = semilocalsa(p,t)$}
\COMMENT{1st phase}
\STATE{$H^{str-sub}_{p,t} = semilocalsa(p,t).stringSubstringMatrix$}
\STATE{$M[j,i] = -H^{str-sub}_{p,t}[i,j]  $}
\STATE{$sufixes = processDiagonal(M,L)$}
\COMMENT{2d phase}
\STATE{$W_2 = SuffixMaxForEachWindow(sufixes,L_{w})$}
\STATE{$filter(W_2,k_{di})$}
\STATE{ $W_3 = UNIQUE(W_2)$}
\COMMENT{3rd phase unchanged}
\FOR{$w \in W_3$}
\IF{$\exists w^{'} \in W_3:w \subset w^{'} $}
\STATE{ $remove$ $w$ $from$ $W_3$}
\ENDIF
\ENDFOR
\RETURN $W_3$

\end{algorithmic}
\end{algorithm}


\begin{theorem}
Algorithm \ref{alg:patternMathing1} could  be solved in
 $max(O(|t|*|p|),O(|t| * \log |t|))$  time with $O( |t| \log |t|)$ additional space where $p$ is pattern, $t$ is text when $|p| \leq |t|$, $v=O(1)$ where $v$ is denominator of normalized mismatch score for \emph{semi-local sa}
$w_{normalized} = (1,\frac{\mu}{v},0)$.
\end{theorem}

For each phases of algorithm we provide it's time and space bounds.

\paragraph{First phase}.
We will store solution $H$ of \emph{semi-local sa} by decomposing it to permutation matrix $P$ of size $O(v*|t|\times v*|t|)$ (Lines 1-3) (ref add).
The permutation matrix can be stored via two permuations of size $v*|t|$ for column and rows.
It is simply two lists of size $v*|t|$.
Then, to random access query in specific position $i,j$ of matrix $H$ we need to check how many points dominated by $i,j$.
It is just pass through permutations that requires $O(v*|t|)$.
Thus, the total time and space complexity of 1st phase is $O(v *|p| * |t|)$ (time complexity for solving \emph{semi-local sa}) and $O(v*|t|)$.
Given $v=O(1)$ we have $O(|p| * |t|)$ and $O(|t|)$ respectively.
Also random access query for our case is $O(|t|)$.

  


% kernel $P$ has at most $v*|t|$ non zeros (after we use $blow-up$ technique for transition  to \emph{semi-local lcs}).
%Due to the fact that $v = O(1)$, $O(v*|t|)$ becomes $O(|t|)$.
%Note that for such simple data structure we need to calculate the number of %points that dominated by given point to make random access to $P$. It requires %checking at most   $O(|t|)$ points. 

%The solution of \emph{semi-local sa} when $v=O(1)$ is just $O(|t|*p)$.

%The total bounds for time and space complexity for this phase are at most $O(|t|*|p|)$ and $O(|t|)$ correspondingly.

\paragraph{Second phase}
We omit $k$ factor in analysis because when k $\in [\frac{1}{\sqrt{3}},1]$ $O(k) = 1$

We will use the first approach described in the algorithm description for this phase.
First, although the random access query to a matrix element requires $O(|t|)$.
We only need one such query to step on the diagonal.
Precisely, to the cell that represents substring $t_{0,|p|*k}$, starting at zero position and ending in $|p|*k$ position.  
Further we use \red{Theorem about adjacent cell query} that allows us to perform $O(1)$ access to adjacent elements for given $i,j$ cell in matrix $M$.
Thus, we can visit each cell in the desired diagonal of size at most $O(|t|) * O(|p|) $ in $O(|t|*|p|)$ time in the following way.
Process row $i^{'}$ with starting $j^{'}$ (recall it cell by $M[i^{'},j^{'}]$) position  (go right i.e increment $j^{'}$) until $i^{'}-j \geq |p|*k$.
Then shift by one $i^{'}$ down and $j^{'}$ to right by one if needed (see picture \red{This about the top left corner}).

When we pass through a slice of the specific column, we also will find the longest suffix with the highest similarity simply by checking elements twice.
First for detect maximum score, second for detect the longest suffix among those who have this score.
%It requires storing at most $O(p)$ cells for each column but we only process one column at the time, thus, we will require only $O(p)$ additional space for that whole cell processing.
Thus, for storing for each prefix its longest suffix we need additionally $O(|t|)$ space.
Also for each substring of length $\frac{p}{k}$ we store similarity score by querying them during diagonal passage because they lie also on this diagonal.
Let's denote it by $C$. 
At the end of  $processDiagonal$ we will have $O(t)$ suffixes that require $O(t)$  space for storing them.
Then, $processDiagonal$ requires $O(|t|+|t|*|p|)=O(|t|*|p|)$ time for processing diagonal with $O(|t|+|p|)=O(|t|)$ additional space.
 
Further (Line 5), we need to find longest suffix within $O(|p|)$ window with step one in list of size $|t|$ with additional condition that within each window of size $O(\frac{|p|}{k}-|p|*k)=O(|p|)$ the suffix with length $\frac{p}{k}$ have similarity score at least $-k_{di}$.
It is simply a one-way pass-through list of suffixes where the processing of each window requires at most $O(|p|+1)=O(|p|)$.
More precisely, first, we check that for current window of size $O(|p|)$
associated suffix has similarity not less then given threshold $k_{di}$.
It is simply lookup for a specific element in $C$ with $O(1)$.
If that true, then we need $O(p)$ lookups within $suffixes$ to query the most similar and longest one.    
The total number of such windows at most $O(|t|)$.
Thus, $SuffixMaxForEachWindow$ requires $O(|t|)*O(|p|)=O(|t|*|p|)$ time with $O(|t|)$ space for storing suffix for each window. 

The filtering process (Line 6) is a one-way pass through a list of suffixes $W_2$.
It requires at most $O(t)$ time.

As we see, the total running time and space complexity of the second phase is $O(|t|*|p|)$ and $O(|t|)$ respectively.

\paragraph{Third phase}
The third phase remains unchanged, thus have the same time and space-bound.
Note that it possible to perform this phase in-place during a second phase which 
make the algorithm even faster i.e decrease space and time complexity to $O(|t|)$  and $O(|t|*|p|)$.
The third phase is $O(|t| log|t|)$  at most both for space and running time complexity.

Thus, the total running time is $max(O(tp),O(t \log t))$ and space complexity $O(t \log t)$. \red{It be good if we also improve third phase)))}


\begin{theorem}
Algorithm \ref{alg:patternMathing1} preserves completnesses property of algorithm \cite{luciv2019interactive} with scoring scheme  $w = (0,-2,-1)$ and have running time and space complexity $max(O(tp),O(t \log t))$ and $O(t \log t)$  respectively.
\end{theorem}

First, note  that \emph{edit distance} in algorithm \cite{.} may be expressed as sequence alignment  with following scoring scheme: 
\begin{displaymath}
w_{sa}=(w_{+},w_{0},w_{-}) = (0,-2,-1)
\end{displaymath}
Then to get intial $edit score$ we need to apply inverse operation:
\begin{equation}\label{editsa}
editscore(a,b) = -sa(a,b,w_{sa}) 
\end{equation}

Next, $w_{sa}$ may be normalized using normalization \ref{weightNormalization}:
\begin{displaymath}
(0, -2, -1) \rightarrow (1,\frac{\mu=0}{v=1}, 0)
\end{displaymath}
Thus, $d_{di} \leq k_{di}$ is the same as $sa \geq -k_{di}$.

Second, let's carefull review phases 1 and 2 of given algorithms.
At first algorithm \ref{.} pass through text $t$ with sliding window to detect those fragments which has edit score above given threhsold $k_{di}$ with size $\frac{p}{k}$.
Then within these fragments algorithm detects longest suffixes most similar to pattern $p$ with size within  $pk...\frac{p}{k}$ interval.
Algorithm \cite{.} proceeds in very similar but ,informally, phases are swapped.
First, it detects longest suffixes with size in $pk...\frac{p}{k}$ interval for each prefix of text $t$.
Then it proceeds in a such way that for each window of size $L_{w}$ the longest suffix is detected that have aligment score between current window and pattern $p$ below given threshold $-k_{di}$.
Due to formula  \emph{editsa} the resulting set of second phases of two algorithms is equals.
The third phase is unchaned in algorithm \cite{.}.
Thus, algorithm \cite{}  preserves  completnessess property.
For given $w = (0,-2,-1)$ we have $v=1$ then wehave running time as claimed.


%At first algorithm \ref{luciv} pass through text $t$ with sliding window to detect those fragments which has similarity abobe given threhsold $k_{di}$ with size $\frac{p}{k}$.
%Then within these fragments algorithm detects longest suffixes most similar to pattern $p$ with size within  $pk...\frac{p}{k}$ interval.
%That how $A_1$ constucted.
%
%T%he second algorithm \ref{alg:patternMathing1} proceed in similar way but it first .
 .
%$Then filtering is perfomed in that way that only$
%That how $A_1$ constucted.
%those lonh suffices  left 
 %for those windows of size $\frac{p}{k}$ the longest suffix is left.

%T%%hus, $A_1=A_2$  by resulting equivalence of construction. 

