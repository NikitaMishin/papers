\section{Algorithm for near duplicate detection}
\label{section:luciv}

We now describe an improved version of Luciv et.al. algorithm \cite{luciv2019interactive} by utilizing a \emph{semi-local sa} solution.
Then we present proof that improved version preserves completnesess property.
It is achieved by imitating all phases of the algorithm. 
 

\subsection{Algorithm description}

The algorithm comprises three phases as in \cite{luciv2019interactive}.
At phase one (Lines 1-3) semi-local sa problem is solved for the pattern $p$ against whole text $t$.
This solution provides access to the string-substring matrix $H^{str-sub}_{p,t}$ which allows performing fast queries of \emph{sa} score for pattern $p$ against every substring of text $t$.
We apply implicitly transposition and inverse operation on $H^{str-sub}_{p,t}$:

\begin{equation}
	M[j,i]:= -H^{str-sub}_{p,t}[i,j]
\end{equation}
Note that, inverse operataion preserves (\emph{anti}) \emph{Monge} property whereas inverse operation make \emph{anti Monge} matrix \emph{Monge} and vice versa. 
So, matrix $M$ is \emph{Monge} matrix.

The second phase consist of several steps (Lines 4-6).
First, we want to obtain for each prefix of the text $t$ a longest suffix that have a highest similarity with given pattern $p$ with following constarint.
The lengths of obtained suffixies should be in $|p|*k..\frac{|p|}{k}$ interval where $k \in [\frac{1}{\sqrt{3}},1]$.
It could be done in several way.
For example, direct pass through diagonal with width $w:= \frac{|p|}{k} - |p|*k = |p|(\frac{1}{k} - k)$ in $H^{str-sub}_{p,t}$ (see fig) or in $M$ (see fig).
The other approach is following.
Note that in  $M$ is \emph{Monge matrix} and  indices is swapped.
It allows us to descry this diagonal as approximately $|t|$ square windows of size $wxw$ i.e a sliding window of step 1 that goes diagonally.
Due to lenght constraint we only interesting in elements that lies in main diagonal and below it.
Each of this $W:=wxw$ matrix is \emph{Monge matrix} by definition.
This implies that $W$ also totally monotone.
If we set to $+\inf$ that lies above diagonal that matrix will remain totally monotone.
Thus, we can apply \emph{SMAWK} algorithm to this matrix to find leftmost element that has minimum in a given row with corresponding column position.
For our case leftmost means that for each prefix algorithm will detect longest suffix (remember that $M$ is transposed $H^{str-sub}_{p,t}$ ).

Second step, it is simply one way pass through these suffixes with sliding window  of size $\frac{|p|}{t}$ to find for each window most similar suffix with the longest length. Then resulting set is filtered out that remaining suffixes have score greater or equal to given theshold $-k_{di}$. 

The third phase is same as in \cite{luciv2019interactive} (Lines 8-12).  



%At the second phase text $t$ is scanning with a sliding window of length $L_{w}$ with step 1.
%First, it checks that given substring $w$ that of a maximum possible size of $L_{w}$ have score that is higher or equal to a given threshold (Line 4).
%If no, then this interval will not further be proceeded (Line 5) else this interval will be processed as follows.
%First, for each prefix of text $t$ it finds suffix that has the highest alignment score with the maximal length among all suffixes with that score. 
%It corresponds to the searching row position for each column in string-substring matrix with associated alignment score. 
%Second, among these suffixes, one is selected with the highest score.
%If several suffixes have the same score the one with maximal length is selected (Line 8).
%Then if selected suffix has score higher than the threshold, then it is added to set $W_2$.

%The third phase is the same as in \cite{luciv2019interactive}. 
%More precisely, on the third phrase, set $W_{2}$ is filtered out in a such way that only non-intersected intervals are left.
%It is simply the sorting of set $W_{3}$ by starts of intervals with following one way passage with filtering.  


\begin{algorithm}[H]
\caption{PATTERN BASED NEAR DUPLICATE
SEARCH ALGORITHM VIA SEMI-LOCAL SA}
\label{alg:patternMathing1}
Input: pattern $p$, text $t$, similiarity measure $k \in  [ \frac{1}{\sqrt{3}} ,1  ]$\\
Output: Set of non-intersected clones of pattern $p$ in text $t$
\begin{equation}
    k_{di}=|p|*(\frac{1}{k}+1)(1-k^2)
\end{equation}
\begin{equation}
 L_{w} = \frac{|p|} {k}
\end{equation}
\begin{equation}
  w = |p|(\frac{1}{k} - k)
\end{equation}
Pseudocode:
\begin{algorithmic}[1]
\STATE{$W = semilocalsa(p,t)$}
\COMMENT{1st phase}
\STATE{$H^{str-sub}_{p,t} = semilocalsa(p,t).stringSubstringMatrix$}
\STATE{$M[j,i] = -H^{str-sub}_{p,t}[i,j]  $}
\STATE{$sufixes = processDiagonal(M,L)$}
\COMMENT{2d phase}
\STATE{$W_2 = SuffixMaxForEachWindow(sufixes,L_{w})$}
\STATE{$filter(W_2,k_{di})$}
\STATE{ $W_3 = UNIQUE(W_2)$}
\COMMENT{3rd phase unchanged}
\FOR{$w \in W_3$}
\IF{$\exists w^{'} \in W_3:w \subset w^{'} $}
\STATE{ $remove$ $w$ $from$ $W_3$}
\ENDIF
\ENDFOR
\RETURN $W_3$

\end{algorithmic}
\end{algorithm}


\begin{theorem}
Algorithm \ref{alg:patternMathing1} could  be solved in
 $max(O(tp),O(t \log t))$  time with $O(t \log t)$ additional space where $p$ is pattern, $t$ is text when $|p| \leq |t|$, $v=O(1)$ where $v$ is denominator of normalized mismatch score for \emph{semi-local sa}
$w_{normalized} = (1,\frac{\mu}{v},0)$.
\end{theorem}

For each phases of algorithm we provide it's time and space bounds.

\paragraph{First phase}.

For storing \emph{semi-local lcs} solution, specifically decomposed kernel $P$ we will use simply two list (two permuations) of size at most $v*|t|$ each because kernel $P$ has at most $v|t|$ non zeros (after we use $blow-up$ tecnique).
Due to fact that $v = O(1)$    $O(v*|t|)$ becomes $O(|t|)$.
Note that for such simple data structure to make random access to $P$ we need to calculate amount of poinst that dominated by given point. It require to check at most   $O(|t|)$ points. 
Thus, random access query is $O(|t|)$.

The solution of $semi-local sa$ when $v=O(1)$ is just $O(|t|*p)$.

The total bounds for time and space complexity for this phase is at most $O(|t|*p)$ and $O(|t|)$ correspondingly.

\paragraph{Second phase}
We omit $k$ factor in analysis because when k $\in [\frac{1}{\sqrt{3}},1]$ $O(k) = 1$

We will use first approach described in algorithm description for this phase.
First, although the random access query to matrix element require $O(t)$.
We only need one such query to step on the diagonal.
Further we use \red{Theorem about adjacent cell query} that allows us to perform $O(1)$ access to adjacent elements for given $i,j$ cell in matrix $M$.
Thus, the visit of each cell in diagonal of size at most $O(t) \times O(p) $ require at most $1$ random access and $O(t*p -1) =O(t*p)$ adjacent accesses.
When we pass through slice of specific column we also will find the longest suffix with highest similarity.
It requires at most store $O(p)$ cells for each column but we only process one column at the time, thus, we store only  additional $O(p)$ for that whole cell processing.
Also we store $O(t)$ cells that corresponds to suffixes of length $\frac{p}{k}$  
At the end of  $processDiagonal$ we will have $t$ suffixes that requires $O(t)$  space for storing them.
Then, $processDiagonal$ requires $O(t+tp)=O(t)$ time for processing diagonal with $O(t+p)=O(t)$ additional space. 
Further, we need to find longest suffix within $O(|p|)$ window with step one in list of size $|t|$ with additional condition that within each window the suffix with length $\frac{p}{k}$ have similarity score at least $-k_{di}$.
It is simply one way pass through list of suffixes where processing of each window requires at most $O(p+1)=O(1)$.
The total number of such windows at most $O(t)$.
Thus, $SuffixMaxForEachWindow$ requires $O(t)*O(p)=O(tp)$ time with at $O(t)$ space for storing suffix for each window. 

The filtering process is one way pass throgugh list of suffixes $W_2$.
It requires at most $O(t)$ time.

As we see, the total running time and space complexity of second phase is $O(tp)$ and $O(t)$ respectively.

\paragraph{Third phase}
The third phase remains unchanged, thus have the  same time and space bound.
Note that it possible for perform this phase in-place during second phase which 
make algorithm faster.
The third phase is $O(|t| log|t|)$  at most both for space and running time complexity.

Thus, the total runing time is $max(O(tp),O(t \log t))$ and space complexity $t \log t$. \red{It be good if we also improve third phase)))}


\begin{theorem}
Algorithm \ref{alg:patternMathing1} preserves completnesses property of algorithm \cite{luciv2019interactive}.

\end{theorem}

Let be $A_1$ a set $W_{2}$ from algorithm \ref{luciv}.
Let be $A_2$ a set $W_{2}$ from algorithm \ref{alg:patternMathing1}.
We will show that $A_2 = A_1$.

At first algorithm \ref{luciv} pass through text $t$ with sliding window to detect those fragmetns which has similarity abobe given threhsold $k_{di}$ with size $\frac{p}{k}$.
Then within these fragments algorithm detects longest suffixes most similar to pattern $p$ with size in  $pk...\frac{p}{k}$ interval.

The second algorithm \ref{alg:patternMathing1} proceed in similar way but it first detects longest suffixes with size in $pk...\frac{p}{k}$ interval for each prefix of text $t$.
Then filtering is perfomed in that way that only for those windows of size $\frac{p}{k}$ the longest suffix is left.

Thus $A_1=A_2$  



  

Note that set $A_{1}$ contains only those fragments of size $\frac{p}{k}$ from text $t$ that close enough to pattern $p$ i.e 

The fragment from $W_{1}$ then shrunked.
It means that after second phase set $W_{2}$ will have size  of $W_{1}$. 
