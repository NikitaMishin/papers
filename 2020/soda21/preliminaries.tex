\section{Preliminaries}
\label{section:preliminaries}

\subsection{Approximate pattern matching}
The approximate pattern matching problem ($AMatch$) defined as follows.
Given text $t$, pattern $p$ and some threshold $h$ the \emph{approximate pattern matching} problem ask for all substrings from text $t$ that have similarity score  with given pattern $p$ at least $h$ according to some similarity function $g$.  

There exist different kinds of extensions and particular cases of this problem.
For example, \emph{complete approximate pattern matching} (\emph{CompleteMatch}) that ask for
substrings of text $t$ that are exact clones of pattern $p$.
The approach for this special case of \emph{AMatch} is usage of well-know  algorithms such as  Aho-Korasic, BouerMurr, Knuth-Morris-Pratt, and so on.
The latter one have optimal running time complexity of $O(|p|+|t|)$ for \emph{CompleteMatch} problem\cite{}.
\emph{Approximate pattern matching with k mismatches} is an another example of special case \cite{}.
The search of \emph{pattern with wildcard symbols} or search set of patterns in text $t$\cite{}, multidimensional \emph{AMatch}\cite{} , search with lenght constraint of detected duplicates \cite{} are examples of such extension.
There exits many more examples of constrainsts, extensions and special cases of \emph{AMatch} problem\cite{}.

The one of the common approach to solve approximate pattern matching is the usage of solution of  string  similarity problem.
Latter represent a set of fundamental problems such as \emph{edit distance}, \emph{longest common subsequence}, \emph{sequence alignment}.
In this paper we primarily focuses on the usage of latter two when developing algorithms.

Recently there have been developed algorithm for solving interesting  extension of \emph{AMatch} problem with length constarint\cite{•}.
Although their algorithm have poor result in terms of running time complexity, the proposed solution possesses  a completnessess proprety i.e it founds \emph{all} non-intersected clones of pattern $p$ with specified similarity threshold  and length constraint on matching substrings.
Thus, this algorithm is an subject of interest in this paper.
The complete description of algorithm and its improved version may be found in section \ref{•} respectively.


\subsection{Semi-local lcs}
First of all we give definition of \emph{lcs} and \emph{sa}.

\begin{definition}
Given two strings $a$ and $b$  the longest common subsequence (\emph{LCS}) problem ask for the maximal length of the longest common subsequence of $a$ and $b$ (\emph{lcs(a,b)}).
\end{definition} 
In other words, \emph{LCS} problem asks about maximal lcs score of two given string a and b ($lcs(a,b)$).

\begin{definition}
Given two strings $a$ and $b$ and scoring scheme $w=(w_{+},w_{0},w_{-})$  the sequence alignment (\emph{SA}) problem ask for the maximal alignment score between $a$ and $b$ ($sa(a,b)$).
\end{definition}

Scoring scheme determines how calulate alignment score of two aligned sequences.
If pair of character in aligned sequences are matches (equals) then this pair  contributes to final alignemnt score $w_{+}$, if their mismatch it contributes $w_{0}$.
If symbol $\alpha$ of one of the sequences is not aligned with  any other symbol from other sequence it means that $\alpha$ is aligned with $gap$.
Thus, this pair contributes $w_{0}$.    
The scoring scheme calculates as follows:
\begin{equation}\label{formula:sa}
\begin{aligned}
    sa(a,b,w) = w_{+}k^{+} + w_{0}k^{0} + w_{-} (|a| + |b| - 2k^{+} - 2k^{0}) =\\
    k^{+} (w_{+} - 2w_{-} ) + k^{0}  (w_{0} - 2w_{-}) + w_{-}(|a| + |b|)
\end{aligned}
\end{equation}
The $k^{+}$ states for the number of matching symbols, $k^{-}$ --- mismatched symbols. 

Note that  \emph{LCS} is a special case of \emph{SA} when scoring scheme is $(1,0,0)$.

Both described problems are solved by  classical dynamic programming algorithm and have running time complexity $O(|a||b|)$.
$LCS$ and $SA$ allow you to find how much whole given strings are similar i/e how similar two string in a global sense.

In many cases, this is not enogh.
There also exist fully local version of these problems and semi-local one.
The last one is in sight of this paper due to natural applicability to approximate pattern matching. 
\subsection{Semi-local lcs}

Given two strings $a$ and $b$ the semi-local lcs is asks about
lcs scores for following:
\begin{enumerate}
\item \emph{string-substring}: whole $a$ against every substring of $b$
\item \emph{substring-string}: whole $b$ against every substring of $a$
\item \emph{prefix-suffix}: every prefix of $a$ against every suffix of $b$
\item \emph{suffix-prefix}: every prefix of $b$ against every suffix of $a$
\end{enumerate} 


The following \emph{semi-local lcs matrix} associated with the defined \emph{semi-local lcs}.
\begin{definition}
The \emph{semi-local lcs matrix}  $H_{a,b}$ for strings a,b defined as follows:
\begin{equation}
	H_{a,b}[i,j] = if (j\leq i) j-i  else lcs(a,b^{pad}[i,j]) 
\end{equation} 
where $i \in [-|a|:|b|], j \in [0:|a|+|b|] $ and $b^{pad}= ?^{|a|}b?^{|a|}$, $?$--- wildcard symbol that matches any other symbol.
\end{definition}
The semi-local lcs matrix $H_{a,b}$ comprises from four
quadrant associated with described  subproblems:
\begin{equation}
 H_{a,b} = \begin{bmatrix}
H_{a,b}^{suf-pre} & H_{a,b}^{sub-str} \\
H_{a,b}^{str-sub} & H_{a,b}^{pre-suf} 
\end{bmatrix}    
\end{equation}

\begin{definition}
Matrix $H$ called (anti) Monge matrix if

\begin{displaymath}
H[i,j]+H[i^{'},j^{'}] (\geq)\leq H[i,j^{'}]+H[i^{'},j], \forall i<=i^{'}, j \leq j^{'}
\end{displaymath}
\end{definition}

\begin{definition}
Let $H[0:m,0:n]$  be a matrix.
$H^{\square}[0:m-1,0:n-1]$ constructed as a result of taken cross difference between secondary and first diagonal for all adjacent 2 by 2 squares called \emph{cross-difference} matrix of  $H$
\end{definition}


\begin{definition}
Matrix $H$ called unit anti Monge matrix if $H$ is (anti) Monge matrix and its \emph{cross-difference matrix} $(-)H^{\square}$ is permutation matrix.
\end{definition}
The example of unit anti Monge matrix is following:
\begin{equation}
\begin{bmatrix}
0 & 2 & 3 \\
0 & 1 & 2 \\
0 & 1 & 1
\end{bmatrix} ^ { \square} =
\begin{bmatrix}
(2 + 0) - (1 + 0)  & (3 + 1) - (2 + 2)  \\
(1 + 0) - (1 + 0) &  (2 + 1) - (1 + 1) 
\end{bmatrix} = 
\begin{bmatrix}
1 & 0  \\
0 & 1 
\end{bmatrix} 
\end{equation}
 


\begin{definition}
Let $H[0:m-1,0:n-1]$  be a matrix.
$H^{\nearrow}[0:m,0:n]$ constructed as sum of element that lies below and left given cell $i,j$ in matrix $H$ called \emph{dominance-sum} matrix of $H$
\end{definition}

The example dominance sum matrix:
\begin{equation}
\begin{bmatrix}
1 & 0  \\
0 & 1 
\end{bmatrix}^{\nearrow} =
\begin{bmatrix}
0+0+0 & 1 & 1+1 \\
0+0 & 0 & 1 \\
0 & 0 & 0
\end{bmatrix} =
\begin{bmatrix}
0 & 1 & 2 \\
0 & 0 & 1 \\
0 & 0 & 0
\end{bmatrix}
\end{equation}

In \cite{tiskin} is proved that $H_{a,b}$ is unit anti Monge.
Also it is proved that  this matrix may be decomposed to permuation matrix i.e into \emph{cross-difference} matrix.
It allows to store $H_{a,b}$ implicitly and query any element of $H_{a,b}$ via dominance sum query (orthogonal range queries).
Thus, there may be several ways to storing matrix $H_{a,b}$ or one of it quadrant implicitly.
A simple storing of two list of permutation gives $O(|a|+|b|)$
space and time complexity with $O(|a|+|b|)$ orthogonal range queries (need to check  how many points dominated by given point), whereas more sophisticated approach requires
$O(|a|+|b|)$  space with $O( (|a|+|b|) \sqrt{\log{ (|a| +|b|)} } )$ preprocessing time and allows to query any point of $H$ in $O(\frac{\log (|a|+|b|)}{\log \log (|a|+|b|)})$ time.  

The one useful proposition of $H$ is following.
\begin{proposition}\cite{}
Given a permutation matrix $P$ and the value
$P^{\nearrow}[i; j]$, the values $P^{\nearrow}[i +- 1; j], P^{\nearrow}[i; j +- 1]$, where they exist, can
be queried in time $O(1)$\cite{}.
\end{proposition}


We particulary interesting in lower left quadrant that refers to string substring problem:
\begin{equation}
H_{a,b}^{str-sub}[i,j] = lcs(a,b[i,j]),i,j \in [0,|b|] 
\end{equation}

There exists several algorithms \red{second on,recursive not described as i see} that solve \emph{semi-local lcs}.
Both have the optimal running time $O(|a||b|)$ for given dynamic problem\cite{}\red{Impossibility faster then pt}.

\subsection{Semi-local sa}
The semi-local sequence alignment (sa) is a generalazation of semi-local lcs in same sense as sequence alignemnt is generelaztion of lcs.

Given two strings $a$ and $b$ and scoring scheme $w=(w_{+},w_{0},w_{-})$  the semi-local sa  asks about
sa scores for following:
\begin{enumerate}
\item \emph{string-substring}: whole $a$ against every substring of $b$
\item \emph{substring-string}: whole $b$ against every substring of $a$
\item \emph{prefix-suffix}: every prefix of $a$ against every suffix of $b$
\item \emph{suffix-prefix}: every prefix of $b$ against every suffix of $a$
\end{enumerate} 

The associated matrix for \emph{semi-local sa} is defined analogously as for \emph{semi-local lcs}.

The approach for solving \emph{semi-local sa} is as follows.
The problem reduced to \emph{semi-local lcs}.
First, note that scoring scheme in \ref{formula:sa}
may be simplified by so called normalization\cite{}:
\begin{equation}\label{weightNormalization}
    \begin{aligned}
    w = (w_{+}, w_{0} , w_{-}) \xrightarrow{} (w_{+} +2x , w_{0} + 2x , w_{-} + x) =\\ ( \frac{w_{+} +2x}{w_{+} +2x} , \frac {w_{0} + 2x}{w_{+} +2x} , \frac{w_{-} + x}{w_{+} +2x})_{x=-w_{-}} = (1,\frac{\mu}{v} ,0) 
    \end{aligned}
\end{equation}
The resulted scoring scheme $w_{normalized} = (1,\frac{\mu}{v} ,0)$ called normalized scoring scheme.

Then to query initial score $sa$ for scoring scheme $w$
knowing $sa_{normalized}$ for $w_{normalized}$ you need to apply reverse regularization:
\begin{equation}
    \begin{aligned}
    sa(a,b,w) = sa_{normalized}  (w_{+} - 2w_{-}) +  w_{-} (|a| + |b|)
\end{aligned}
\end{equation}

The blown-up tecnhique is applied after reducing scoring scheme
which increases both input strings in $v$ times.
Nonetheless, only one of the described algorithm time complexity increases in $v^{2}$ times, the second one only $v$. \red{Bad sentecnce}.
The space complexity also increses by factor $v$. 
%(we store permitation matrix of size $(v(|a|+|b|) \times v(|a|%%+|b|) $) 

%Thus, the rinning time and space complexity of semi-local sa is %$(v(|a|+|b|) \times v(|a|+|b|) $ and 

For detalied description we refer readers to TISKIN BOOK\cite{}.

 
\subsection{Range maximum/minimum queries}

Range maximum/minimum queries (\emph{rmq}) (submatrix query)  refers to search maximum/minimum element in submatrix $[i_{1}:i{_2}]\times [j_{1}:j{_2}]$ of given matrix $M$ of size $n\times n$.
The associated data strucutre that can report maximum/minimum element in any  submatrix query called \emph{range maximum/minimum data structure}.

For the generic case of Matrix $M$ it is not possible to
achieve running time faster then $O(n^2)$ due to fact that storing matrix $M$ requires $O(n^2)$.

Nonetheless, the situation is changed if we  consider special cases such as Monge matrices.
%Monge matrices can  be (and often) stored implicilty.
There have been several researches over several decades about 
rmq on monge matrices \cite{}.

The recent research achives following result\cite{}.

\begin{theorem}\cite{}
Given an $n \times n$ Monge matrix $M$, a data structure of size $O(n)$ can be constructed
in $O(n \log n)$ time to answer submatrix maximum queries in $O(\log \log n)$ time when random access to Monge matrix is $O(1)$.
\end{theorem}


\begin{theorem}\cite{}
Given an $n \times n$ staircase\footnote{Defintion} Monge matrix $M$, a data structure of size $O(n)$ can be
constructed in $O(n \log n$) time to answer submatrix maximum queries in $O(\log \log n$) time when random access to Monge matrix is $O(1)$.
\end{theorem}


\begin{theorem}\cite{}
Given an $n \times n$ partial Monge matrix\footnote{Definition} $M$, a data structure of size $O(n)$ can be
constructed in $O(n \log n$) time to answer submatrix maximum queries in $O(\log \log n$) time when random access to Monge matrix is $O(1)$.
\end{theorem}

The above results applies both to range  minimum queries and to monge matrices with non-constant access $O(\beta)$ to queries.
The latter one, costs in  increased construction time and query time by factor $\beta$. 

  
%\begin{definition}
%Given  query of type $i_{1},i_{2},j_1,j_2, i_1,i_2 \in [0,]$
%\end{definition}
%\emph{rmq}  





\subsection{Near-duplicate detection algorithm}
First, we denote several parameters, that is used in algorithm \cite{}.
$k$--- constant in interval $[\frac{1}{\sqrt{3}},1]$ that set similarity measure.  
A window $w$ of size $L_{w} = |p|/k$ is to process text $t$ with
sliding window of one symbol step.
$k_{di} = |p|*(\frac{1}{k}+1)(1-k^2)$ is threshold value for edit distance.
$I$ --- interval of size $[|p|k,\frac{|p|}{k}]$ that set boundaries for lenght of matching substrings.
$d_{di}$ --- function that measure similarity between two strings.

The algorithm comprises of three phases.

At the first phrase  text $t$ is processed with sliding window of size $L_{w}$ with one symbol step.
Further, substrings that corrsepond to window $w$ compared using edit distance\footnote{Authors of \cite{} used lcs edit distance --- where  operations substituion,removoval, addition of one symbol costs 2,1,1 respectively} and if $d_{di}(p,t_{w}) \leq k_{di}$ i.e  close enough, then they saved to set $W_{1}$ to be further proceeded. 

On the second phase  each of the detected substrings in $W_{1}$ are shrunk i.e they lenght could be decreased.
More preciesely, within each of the element of $W_{1}$ the largest one substring with legnth fall in $I$ that most similar to pattern $p$ according to $d_{di}$ is selected.
The set $W_{2}$ is a result of this phase.

At the final third phase  set $W_{2}$ iterated over to remove elements that fully contains in ohter elements of $W_{2}$ or duplicates.

\paragraph{Running time analysis}
\emph{1st phase}.The first phase requires at most  $O(|t||p|^2)$ due to fact
that computing cost of edit distance is $|p|^2$ for strings of size $O(|p|)$ and we need to process $O(|t|-\frac{|p|}{k})=O(|t|)$ windows.
\emph{2nd phase}. 
The cardinality of set $W_{1}$  at worst case be $O(|t|)$.
Thus, first loop will be iterated over $O(|t|)$ times.
The second loop refers to iteration over $I$ set with cardinality $O(\frac{|p|}{k}-|p|k) = O(|p|)$.
The third loop requires at most $O(|p|)$ since we again goes with sliding window.
The compare operation requires at most $O(|p|^2)$ since both
stirng of size $O(|p|)$.
Thus, the total running time compleixty of second phase is $O(|p|^4|t|)$ at worst case.

\emph{3rd phase}. 
Note that cardinality of set $W_{2}==W_{1}$ and thus at worst case is $O(|t|)$.
Then, this phase requires $O(|t| \log |t|)$ time. 

Thus,the total time complexity of algirthms estimates as 
$O(max(|t||p|^4,|t| \log|t|))$

\begin{theorem}\cite{Luciv}
Compltensess theorem
\end{theorem}

\red{Add luciv pseudocode}